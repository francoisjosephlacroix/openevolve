# OpenEvolve - Free AI Evolution Fork

üöÄ **MAJOR FEATURE: 1,000 FREE AI-GENERATED CANDIDATE SOLUTIONS PER DAY**

This fork's primary breakthrough is enabling **completely free evolutionary algorithm development** through Google's generous Gemini API limits when routing through Gemini CLI. While the base repo only allows you to use an OpenAI-compatible API, **our fork provides 1,000 AI-generated candidate algorithms daily at zero cost** by using a bridge to turn Gemini CLI into an OpenAI-compatible API locally.

## üí∞ Why This Matters

**Traditional AI Evolution Cost Problem:**
- $200-$1,000 per 1,000 code generation requests for models such as Claude 4 or GPT-4
- Most users can't afford extensive algorithm evolution

**Our Solution:**
- ‚úÖ **Google Gemini Free Tier**: 1,000 requests/day on gemini-2.5-flash
- ‚úÖ **Zero API costs** for up to 1,000 evolution candidates daily
- ‚úÖ **Production-quality results** with state-of-the-art Gemini models
- ‚úÖ **Windows compatibility** + comprehensive bridge setup

This enables **serious algorithmic research and optimization** accessible to students, researchers, and developers worldwide without prohibitive costs.

## üÜï What's New in This Fork

### Windows Compatibility Fixes
- ‚úÖ **All evaluation scripts now work on Windows**
- ‚úÖ **Cross-platform path handling** using `os.path.normpath()` 
- ‚úÖ **Subprocess-based timeouts** instead of Unix-only signal handling
- ‚úÖ **Proper Python interpreter detection** using `sys.executable`
- ‚úÖ **Windows shell compatibility** with `shell=True` where needed

### Gemini Integration
- ‚úÖ **Gemini CLI bridge configuration files** for seamless integration
- ‚úÖ **Enhanced OpenAI LLM client** with bridge compatibility
- ‚úÖ **Test scripts** for validating bridge connections
- ‚úÖ **Working circle packing example** with Gemini models

## üöÄ Quick Start on Windows

### Prerequisites
1. **Python 3.8+** installed
2. **Node.js v18+** installed  
3. **Google account** for Gemini API access (free tier: 1,000 requests/day)

### Step 1: Setup Gemini CLI MCP OpenAI Bridge (REQUIRED)

**This bridge is essential** - it converts Gemini CLI into an OpenAI-compatible API that OpenEvolve can use.

```bash
# Clone the bridge fork (includes Windows improvements)
git clone https://github.com/francoisjosephlacroix/gemini-cli-mcp-openai-bridge.git
cd gemini-cli-mcp-openai-bridge

# Install dependencies
npm install

# Build the bridge server
npm run build
```

**One-time Authentication Setup:**
```bash
# Authenticate with Google (opens browser)
node gemini-cli/packages/cli/dist/index.js auth
```

**Start the Bridge Server (keep running):**
```bash
# Start on localhost:8765 (default OpenEvolve expects)
node bridge-server/dist/index.js --port 8765 --host 127.0.0.1

# You should see:
# [BRIDGE-SERVER] [INFO] Server running { port: 8765, host: '127.0.0.1', 
#   mcpUrl: 'http://127.0.0.1:8765/mcp', openAIUrl: 'http://127.0.0.1:8765/v1' }
```

**Keep this terminal running** - OpenEvolve needs the bridge active.

### Step 2: Setup OpenEvolve

**In a NEW terminal window:**
```bash
# Clone this OpenEvolve fork
git clone https://github.com/francoisjosephlacroix/openevolve.git
cd openevolve

# Install Python dependencies
pip install -e .
```

### Step 3: Verify Setup

```bash
# Test bridge connectivity (bridge must be running)
python test_bridge_connection.py

# Test Windows evaluator compatibility  
cd examples/circle_packing
python -c "from evaluator import evaluate; print('‚úÖ Windows compatibility confirmed!')"
```

### Step 4: Run Free AI Evolution!

```bash
# Run circle packing evolution with free Gemini models
# This will generate AI algorithms at zero cost!
python -m openevolve.cli examples/circle_packing/initial_program.py examples/circle_packing/evaluator.py --config config_gemini_bridge.yaml --iterations 5

# For longer runs (up to 1,000 free candidates per day):
python -m openevolve.cli examples/circle_packing/initial_program.py examples/circle_packing/evaluator.py --config config_gemini_bridge.yaml --iterations 100
```

## üìÅ New Configuration Files

### `config_gemini_bridge.yaml`
General Gemini bridge configuration with MCP tool integration.

### `config_circle_packing_gemini.yaml` 
Specialized configuration for circle packing problems with detailed geometric guidance.

### `config_circle_packing_with_tools.yaml`
Enhanced configuration that explicitly instructs Gemini to use MCP tools for research.

## üîß Windows-Specific Improvements

### Evaluation Scripts Updated
All evaluators in `/examples/` have been updated for Windows compatibility:

- `circle_packing/evaluator.py` - Fixed path handling and subprocess execution
- `function_minimization/evaluator.py` - Removed signal dependency  
- `online_judge_programming/evaluator.py` - Added sys.executable usage
- `rust_adaptive_sort/evaluator.py` - Added shell=True for Windows
- `circle_packing_with_artifacts/evaluator.py` - Enhanced path escaping

### Core System Updates
- `openevolve/llm/openai.py` - Enhanced bridge compatibility with `stream=False`

## üß™ Testing

### Test Bridge Connection
```bash
python test_bridge_connection.py
```

### Test Evaluators
```bash
cd examples/circle_packing
python -c "
from evaluator import evaluate
result = evaluate('initial_program.py')
print('Windows compatibility test passed!')
print('Metrics:', result)
"
```

## üìä Performance Results

Tested successfully on Windows with Gemini models:
- **Initial program**: sum_radii = 0.9598, combined_score = 0.3642
- **After 1 iteration**: sum_radii = 0.9798, combined_score = 0.3718
- **Improvement**: +2.1% increase in circle packing efficiency

## üîó Original Project

This is a fork of [OpenEvolve](https://github.com/codelion/openevolve) by CodeLion with Windows compatibility and Gemini integration improvements.

## ü§ù Contributing

Feel free to submit issues and pull requests! This fork focuses on:
- Windows compatibility improvements
- LLM bridge integrations  
- Enhanced evaluation systems
- Cross-platform reliability

## üìÑ License

Same as original OpenEvolve project.
